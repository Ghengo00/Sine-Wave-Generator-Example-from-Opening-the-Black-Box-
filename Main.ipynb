{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d99206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.optimize import root\n",
    "from scipy.linalg import eig\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Set random seed & parameters\n",
    "# -------------------------------\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Network dimensions and task parameters\n",
    "N = 200         # number of neurons\n",
    "I = 1           # input dimension (scalar input)\n",
    "num_tasks = 51  # 51 different sine-wave tasks\n",
    "\n",
    "# Frequencies: equally spaced between 0.1 and 0.6 rad/s\n",
    "omegas = np.linspace(0.1, 0.6, num_tasks)\n",
    "\n",
    "# Static input offset for each task: j/51 + 0.25, j=0,...,50 (j/51+0.25)\n",
    "static_inputs = np.linspace(0, num_tasks-1, num_tasks) / num_tasks + 0.25\n",
    "\n",
    "# Time parameters (in seconds)\n",
    "dt = 0.01       # integration time step\n",
    "T_drive = 1.0   # driving phase duration (to set network state)\n",
    "T_train = 2.0   # training phase duration with static input (target generation)\n",
    "num_steps_drive = int(T_drive/dt)\n",
    "num_steps_train = int(T_train/dt)\n",
    "time_drive = np.arange(0, T_drive, dt)\n",
    "time_train = np.arange(0, T_train, dt)\n",
    "time_full  = np.concatenate([time_drive, T_drive + time_train])\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Define the RNN and its parameters\n",
    "# -------------------------------\n",
    "# The network equations are:\n",
    "#   dx/dt = -x + J tanh(x) + B u + b_x       (1)\n",
    "#   z = w^T tanh(x) + b_z                     (2)\n",
    "#\n",
    "# We represent the parameters as torch.nn.Parameter.\n",
    "# Note: For our simulation we use Euler integration.\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Randomly initialize recurrent weight matrix J with scaling ~1/sqrt(N)\n",
    "J_param = torch.nn.Parameter(torch.randn(N, N, device=device) / np.sqrt(N))\n",
    "# Randomly initialize input weight matrix B of shape (N, I)\n",
    "B_param = torch.nn.Parameter(torch.randn(N, I, device=device) / np.sqrt(N))\n",
    "# Bias for network neurons, shape (N,)\n",
    "b_x_param = torch.nn.Parameter(torch.zeros(N, device=device))\n",
    "\n",
    "# Output weights and bias: readout is scalar.\n",
    "w_param = torch.nn.Parameter(torch.randn(N, device=device) / np.sqrt(N))\n",
    "b_z_param = torch.nn.Parameter(torch.tensor(0.0, device=device))\n",
    "\n",
    "# Collect parameters in a list for optimization\n",
    "params = [J_param, B_param, b_x_param, w_param, b_z_param]\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Simulation function for one trajectory\n",
    "# -------------------------------\n",
    "def simulate_trajectory(x0, u_seq, J, B, b_x, w, b_z, dt):\n",
    "    \"\"\"\n",
    "    Simulate the RNN dynamics with Euler integration.\n",
    "    \n",
    "    Arguments:\n",
    "      x0    : initial state (torch tensor, shape (N,))\n",
    "      u_seq : input sequence (torch tensor, shape (T, I))\n",
    "      J, B, b_x, w, b_z : network parameters (torch tensors)\n",
    "      dt    : time step\n",
    "      \n",
    "    Returns:\n",
    "      xs : (T+1, N) tensor of states over time\n",
    "      zs : (T+1,) tensor of outputs computed as z = w^T tanh(x) + b_z\n",
    "    \"\"\"\n",
    "    T = u_seq.shape[0]\n",
    "    xs = [x0]\n",
    "    zs = []\n",
    "    x = x0\n",
    "    for t in range(T):\n",
    "        # Compute nonlinear activation\n",
    "        r = torch.tanh(x)\n",
    "        # Compute readout\n",
    "        z = torch.dot(w, r) + b_z\n",
    "        zs.append(z)\n",
    "        # Euler integration: dx/dt = -x + J tanh(x) + B u + b_x\n",
    "        u_t = u_seq[t]  # shape (I,)\n",
    "        x = x + dt * (-x + torch.matmul(J, torch.tanh(x)) + torch.matmul(B, u_t)[:,0] + b_x)\n",
    "        xs.append(x)\n",
    "    xs = torch.stack(xs)\n",
    "    zs = torch.stack(zs)\n",
    "    return xs, zs\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Training procedure\n",
    "# -------------------------------\n",
    "# For each of the 51 tasks, we perform:\n",
    "#   (a) Driving phase: u(t) = sin(omega*t) + static_input (to set the state)\n",
    "#   (b) Training phase: u(t) = static_input (constant); target output is sin(omega*t)\n",
    "#\n",
    "# We form the loss as the MSE over the training phase only.\n",
    "#\n",
    "# Note: We use LBFGS as a surrogate for Hessian-free optimisation.\n",
    "\n",
    "def run_batch(J, B, b_x, w, b_z):\n",
    "    loss_total = 0.0\n",
    "    traj_states = []  # store states from training phase for later PCA\n",
    "    fixed_point_inits = []  # store final state from drive phase as an initial guess\n",
    "    # Loop over each task (frequency)\n",
    "    for j in range(num_tasks):\n",
    "        omega = omegas[j]\n",
    "        u_offset = static_inputs[j]\n",
    "        # Build input sequences for both phases:\n",
    "        # Driving phase: u(t) = [ sin(omega*t) + u_offset ]\n",
    "        u_drive = torch.tensor( np.expand_dims( np.sin(omega*time_drive) + u_offset, axis=1), \n",
    "                                dtype=torch.float32, device=device)\n",
    "        # Training phase: static input = [ u_offset ] repeated\n",
    "        u_train = torch.full((num_steps_train, I), u_offset, dtype=torch.float32, device=device)\n",
    "        # Target output during training: sine wave sin(omega*t) with unity amplitude.\n",
    "        target_train = torch.tensor( np.sin(omega * time_train), dtype=torch.float32, device=device)\n",
    "        \n",
    "        # Initialize state at t=0; can be zero.\n",
    "        x0 = torch.zeros(N, device=device)\n",
    "        # First simulate drive phase to set a good initial state.\n",
    "        xs_drive, _ = simulate_trajectory(x0, u_drive, J, B, b_x, w, b_z, dt)\n",
    "        x_drive_final = xs_drive[-1]  # use final state of drive phase as initial condition for training phase\n",
    "        \n",
    "        # Save initial state for fixed point search later.\n",
    "        fixed_point_inits.append(x_drive_final.detach().cpu().numpy())\n",
    "        \n",
    "        # Now simulate training phase with constant input.\n",
    "        xs_train, zs_train = simulate_trajectory(x_drive_final, u_train, J, B, b_x, w, b_z, dt)\n",
    "        # Compute loss: mean squared error between network output and target sine wave.\n",
    "        loss = torch.mean( (zs_train - target_train)**2 )\n",
    "        loss_total += loss\n",
    "        traj_states.append(xs_train.detach().cpu().numpy())\n",
    "    # Average loss over tasks\n",
    "    loss_total /= num_tasks\n",
    "    return loss_total, traj_states, fixed_point_inits\n",
    "\n",
    "# Define LBFGS optimizer (as stand-in for Hessian-free optimization)\n",
    "optimizer = optim.LBFGS(params, lr=1, max_iter=25, history_size=10, line_search_fn=\"strong_wolfe\")\n",
    "\n",
    "num_epochs = 50  # number of training epochs; you may adjust for convergence\n",
    "\n",
    "loss_history = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        loss, _, _ = run_batch(J_param, B_param, b_x_param, w_param, b_z_param)\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    \n",
    "    loss_val = optimizer.step(closure)\n",
    "    loss_history.append(loss_val.item())\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss_val.item():.4f}\")\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Post-Training Analysis: Fixed point search & PCA\n",
    "# -------------------------------\n",
    "# For each task (i.e. for each static input / target omega) we:\n",
    "#   - Simulate the trajectory with the static input (no sine drive)\n",
    "#   - Starting from the final state of the driving phase,\n",
    "#     find a fixed point x* such that:\n",
    "#         f(x*) = -x* + J tanh(x*) + B*u + b_x = 0.\n",
    "#\n",
    "# Also, we compute the Jacobian at the fixed point:\n",
    "#     J_eff = -I + J diag(1 - tanh(x*)^2)\n",
    "# and extract the eigenvalues/eigenvectors for the unstable (complex) mode.\n",
    "\n",
    "def fixed_point_func(x_np, u_val, J_np, B_np, b_x_np):\n",
    "    \"\"\"\n",
    "    Compute f(x) = -x + J*tanh(x) + B*u + b_x for given x and fixed u.\n",
    "    All inputs are numpy arrays.\n",
    "    \"\"\"\n",
    "    x = x_np\n",
    "    return -x + np.dot(J_np, np.tanh(x)) + np.dot(B_np, np.array([u_val])).flatten() + b_x_np\n",
    "\n",
    "def jacobian_fixed_point(x_star, J_np):\n",
    "    \"\"\"\n",
    "    Compute Jacobian: J_eff = -I + J * diag(1 - tanh(x_star)^2)\n",
    "    \"\"\"\n",
    "    diag_term = 1 - np.tanh(x_star)**2\n",
    "    return -np.eye(len(x_star)) + J_np * diag_term[np.newaxis, :]\n",
    "\n",
    "# Extract trained parameters as NumPy arrays\n",
    "J_trained = J_param.detach().cpu().numpy()\n",
    "B_trained = B_param.detach().cpu().numpy()\n",
    "b_x_trained = b_x_param.detach().cpu().numpy()\n",
    "\n",
    "fixed_points = []\n",
    "unstable_eig_freq = []  # store absolute value of imaginary part of unstable eigenvalue\n",
    "\n",
    "# For each task, perform fixed point search using the final state from the drive phase as initial guess.\n",
    "for j in range(num_tasks):\n",
    "    u_const = static_inputs[j]\n",
    "    x0_guess = fixed_point_inits[j]\n",
    "    sol = root(fixed_point_func, x0_guess, args=(u_const, J_trained, B_trained, b_x_trained))\n",
    "    if sol.success:\n",
    "        x_star = sol.x\n",
    "    else:\n",
    "        x_star = x0_guess  # fallback if solver did not converge\n",
    "    fixed_points.append(x_star)\n",
    "    \n",
    "    # Compute Jacobian at the fixed point and its eigen-decomposition\n",
    "    J_eff = jacobian_fixed_point(x_star, J_trained)\n",
    "    eigenvals, eigenvecs = eig(J_eff)\n",
    "    # Find eigenvalue pair with nonzero imaginary part (complex conjugate pair)\n",
    "    idx_complex = np.where(np.abs(np.imag(eigenvals)) > 1e-3)[0]\n",
    "    if len(idx_complex) > 0:\n",
    "        # use the first such eigenvalue\n",
    "        ev = eigenvals[idx_complex[0]]\n",
    "        unstable_eig_freq.append(np.abs(np.imag(ev)))\n",
    "    else:\n",
    "        unstable_eig_freq.append(0.0)\n",
    "\n",
    "# -------------------------------\n",
    "# 6. PCA and Visualization\n",
    "# -------------------------------\n",
    "# Concatenate all states from all tasks (from training phase) to perform PCA.\n",
    "all_states = np.concatenate([traj for traj in traj_states], axis=0)\n",
    "pca = PCA(n_components=3)\n",
    "proj_all = pca.fit_transform(all_states)\n",
    "\n",
    "# For plotting, also project each trajectory and each fixed point into PCA space.\n",
    "proj_trajs = []\n",
    "start = 0\n",
    "for traj in traj_states:\n",
    "    T = traj.shape[0]\n",
    "    proj_traj = proj_all[start:start+T]\n",
    "    proj_trajs.append(proj_traj)\n",
    "    start += T\n",
    "\n",
    "proj_fixed = pca.transform(np.array(fixed_points))\n",
    "\n",
    "# Plot trajectories (blue) and fixed points (green circles) with unstable eigen-directions (red lines)\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for traj in proj_trajs:\n",
    "    ax.plot(traj[:,0], traj[:,1], traj[:,2], color='blue', alpha=0.5)\n",
    "    \n",
    "# Plot fixed points as green circles\n",
    "ax.scatter(proj_fixed[:,0], proj_fixed[:,1], proj_fixed[:,2], color='green', s=50, label=\"Fixed Points\")\n",
    "\n",
    "# For each fixed point, plot the unstable mode as a red line.\n",
    "# We project the eigenvector corresponding to the unstable mode (if available).\n",
    "for j, x_star in enumerate(fixed_points):\n",
    "    u_const = static_inputs[j]\n",
    "    J_eff = jacobian_fixed_point(x_star, J_trained)\n",
    "    eigenvals, eigenvecs = eig(J_eff)\n",
    "    idx_complex = np.where(np.abs(np.imag(eigenvals)) > 1e-3)[0]\n",
    "    if len(idx_complex) > 0:\n",
    "        # select the eigenvector corresponding to one complex eigenvalue\n",
    "        v = eigenvecs[:, idx_complex[0]].real  # take real part for plotting direction\n",
    "        # Scale vector for visualisation\n",
    "        scale = 0.5  \n",
    "        # Project the unstable eigenvector into PCA space\n",
    "        v_proj = pca.transform((x_star + scale * v).reshape(1, -1))[0] - proj_fixed[j]\n",
    "        # Plot a line centered on the fixed point\n",
    "        line = np.array([proj_fixed[j] - v_proj, proj_fixed[j] + v_proj])\n",
    "        ax.plot(line[:,0], line[:,1], line[:,2], color='red', linewidth=2)\n",
    "    \n",
    "ax.set_title('PCA of Network Trajectories and Fixed Points')\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Compare Unstable Mode Frequencies vs. Target Frequencies\n",
    "# -------------------------------\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(omegas, unstable_eig_freq, 'o-', label='|Imag(eigenvalue)| (unstable mode)')\n",
    "plt.plot(omegas, omegas, 'k--', label='Target frequency')\n",
    "plt.xlabel('Target Frequency (rad/s)')\n",
    "plt.ylabel('Frequency from Linearization (rad/s)')\n",
    "plt.title('Comparison of Target Frequencies and Unstable Mode Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComputationalNeuroscience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
