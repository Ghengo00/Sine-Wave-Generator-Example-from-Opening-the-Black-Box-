{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f443253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.optimize import root\n",
    "from scipy.linalg import eig\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Set random seed & parameters\n",
    "# -------------------------------\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Network dimensions and task parameters\n",
    "N = 200         # number of neurons\n",
    "I = 1           # input dimension (scalar input)\n",
    "num_tasks = 51  # 51 different sine-wave tasks\n",
    "\n",
    "# Frequencies: equally spaced between 0.1 and 0.6 rad/s\n",
    "omegas = np.linspace(0.1, 0.6, num_tasks)\n",
    "\n",
    "# Static input offset for each task: j/51 + 0.25, j=0,...,50 (j/51+0.25)\n",
    "static_inputs = np.linspace(0, num_tasks-1, num_tasks) / num_tasks + 0.25\n",
    "\n",
    "# Time parameters (in seconds)\n",
    "dt = 0.02       # integration time step\n",
    "T_drive = 12.0   # driving phase duration (to set network state)\n",
    "T_train = 24.0   # training phase duration with static input (target generation)\n",
    "num_steps_drive = int(T_drive/dt)\n",
    "num_steps_train = int(T_train/dt)\n",
    "time_drive = np.arange(0, T_drive, dt)\n",
    "time_train = np.arange(0, T_train, dt)\n",
    "time_full  = np.concatenate([time_drive, T_drive + time_train])\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Define the RNN and its parameters\n",
    "# -------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Randomly initialize recurrent weight matrix J with scaling ~1/sqrt(N)\n",
    "J_param = torch.nn.Parameter(torch.randn(N, N, device=device) / np.sqrt(N))\n",
    "# Randomly initialize input weight matrix B of shape (N, I)\n",
    "B_param = torch.nn.Parameter(torch.randn(N, I, device=device) / np.sqrt(N))\n",
    "# Bias for network neurons, shape (N,)\n",
    "b_x_param = torch.nn.Parameter(torch.zeros(N, device=device))\n",
    "\n",
    "# Output weights and bias: readout is scalar.\n",
    "w_param = torch.nn.Parameter(torch.randn(N, device=device) / np.sqrt(N))\n",
    "b_z_param = torch.nn.Parameter(torch.tensor(0.0, device=device))\n",
    "\n",
    "# Collect parameters in a list for optimization\n",
    "params = [J_param, B_param, b_x_param, w_param, b_z_param]\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Simulation function for one trajectory\n",
    "# -------------------------------\n",
    "def simulate_trajectory(x0, u_seq, J, B, b_x, w, b_z, dt):\n",
    "    \"\"\"\n",
    "    Simulate the RNN dynamics with Euler integration.\n",
    "    Vectorized implementation for better performance.\n",
    "    \n",
    "    Arguments:\n",
    "      x0    : initial state (torch tensor, shape (N,))\n",
    "      u_seq : input sequence (torch tensor, shape (T, I))\n",
    "      J, B, b_x, w, b_z : network parameters (torch tensors)\n",
    "      dt    : time step\n",
    "      \n",
    "    Returns:\n",
    "      xs : (T+1, N) tensor of states over time\n",
    "      zs : (T+1,) tensor of outputs computed as z = w^T tanh(x) + b_z\n",
    "    \"\"\"\n",
    "    T = u_seq.shape[0]\n",
    "    xs = torch.zeros(T+1, x0.shape[0], device=x0.device)\n",
    "    zs = torch.zeros(T, device=x0.device)\n",
    "    xs[0] = x0\n",
    "    \n",
    "    # Pre-compute B*u for all time steps\n",
    "    Bu = torch.matmul(B, u_seq.transpose(0, 1)).transpose(0, 1)  # shape (T, N)\n",
    "    \n",
    "    # Main simulation loop\n",
    "    for t in range(T):\n",
    "        x = xs[t]\n",
    "        # Compute nonlinear activation\n",
    "        r = torch.tanh(x)\n",
    "        # Compute readout\n",
    "        zs[t] = torch.dot(w, r) + b_z\n",
    "        # Euler integration: dx/dt = -x + J tanh(x) + B u + b_x\n",
    "        xs[t+1] = x + dt * (-x + torch.matmul(J, r) + Bu[t] + b_x)\n",
    "    \n",
    "    return xs, zs\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Training procedure and visualization\n",
    "# -------------------------------\n",
    "def run_batch(J, B, b_x, w, b_z):\n",
    "    \"\"\"\n",
    "    Run a batch of tasks with improved memory efficiency and GPU utilization.\n",
    "    \"\"\"\n",
    "    loss_total = 0.0\n",
    "    traj_states = []  # store states from training phase for later PCA\n",
    "    fixed_point_inits = []  # store final state from drive phase as an initial guess\n",
    "    \n",
    "    # Pre-allocate tensors for all tasks\n",
    "    x0 = torch.zeros(N, device=device)\n",
    "    \n",
    "    # Process tasks in smaller batches to manage memory\n",
    "    batch_size = 10  # Adjust based on available memory\n",
    "    for batch_start in range(0, num_tasks, batch_size):\n",
    "        batch_end = min(batch_start + batch_size, num_tasks)\n",
    "        batch_loss = 0.0\n",
    "        \n",
    "        # Pre-compute input sequences for the batch\n",
    "        u_drive_batch = []\n",
    "        u_train_batch = []\n",
    "        target_train_batch = []\n",
    "        \n",
    "        for j in range(batch_start, batch_end):\n",
    "            omega = omegas[j]\n",
    "            u_offset = static_inputs[j]\n",
    "            \n",
    "            # Build input sequences for both phases\n",
    "            u_drive = torch.tensor(np.sin(omega*time_drive) + u_offset, \n",
    "                                 dtype=torch.float32, device=device).view(-1, 1)\n",
    "            u_train = torch.full((num_steps_train, 1), u_offset, \n",
    "                               dtype=torch.float32, device=device)\n",
    "            target_train = torch.tensor(np.sin(omega * time_train), \n",
    "                                      dtype=torch.float32, device=device)\n",
    "            \n",
    "            u_drive_batch.append(u_drive)\n",
    "            u_train_batch.append(u_train)\n",
    "            target_train_batch.append(target_train)\n",
    "        \n",
    "        # Process each task in the batch\n",
    "        for j, (u_drive, u_train, target_train) in enumerate(zip(\n",
    "            u_drive_batch, u_train_batch, target_train_batch)):\n",
    "            \n",
    "            # Simulate drive phase\n",
    "            xs_drive, _ = simulate_trajectory(x0, u_drive, J, B, b_x, w, b_z, dt)\n",
    "            x_drive_final = xs_drive[-1]\n",
    "            \n",
    "            # Save initial state for fixed point search\n",
    "            fixed_point_inits.append(x_drive_final.detach().cpu().numpy())\n",
    "            \n",
    "            # Simulate training phase\n",
    "            xs_train, zs_train = simulate_trajectory(x_drive_final, u_train, J, B, b_x, w, b_z, dt)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = torch.mean((zs_train - target_train)**2)\n",
    "            batch_loss += loss\n",
    "            \n",
    "            # Store trajectory states\n",
    "            traj_states.append(xs_train.detach().cpu().numpy())\n",
    "            \n",
    "            # Clear intermediate tensors\n",
    "            del xs_drive, xs_train, zs_train\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        # Accumulate batch loss\n",
    "        loss_total += batch_loss\n",
    "        \n",
    "    # Average loss over all tasks\n",
    "    loss_total /= num_tasks\n",
    "    return loss_total, traj_states, fixed_point_inits\n",
    "\n",
    "# Define LBFGS optimizer with more conservative parameters\n",
    "optimizer = optim.LBFGS(params, lr=0.6, max_iter=10, history_size=10, line_search_fn=\"strong_wolfe\")\n",
    "\n",
    "num_epochs = 50  # number of training epochs\n",
    "loss_history = []\n",
    "best_loss = float('inf')\n",
    "best_params = None\n",
    "loss_threshold = 1e-4  # threshold for early stopping\n",
    "\n",
    "class TrainingState:\n",
    "    def __init__(self):\n",
    "        self.traj_states = []\n",
    "        self.fixed_point_inits = []\n",
    "\n",
    "state = TrainingState()\n",
    "\n",
    "# Track training time\n",
    "start_time = time.time()\n",
    "print(\"Starting training...\")\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Training epochs\"):\n",
    "    # Clear memory between epochs\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "    \n",
    "    def closure():  # required by the LBFGS optimizer to re-evaluate the model function multiple times per step\n",
    "        optimizer.zero_grad()\n",
    "        loss, state.traj_states, state.fixed_point_inits = run_batch(J_param, B_param, b_x_param, w_param, b_z_param)\n",
    "        loss.backward() # computes the gradient of the loss with respect to the model parameters\n",
    "        return loss\n",
    "    \n",
    "    try:\n",
    "        loss_val = optimizer.step(closure)\n",
    "        loss_history.append(loss_val.item())    # returns the computed loss value for the epoch\n",
    "        \n",
    "        # Save best parameters\n",
    "        if loss_val.item() < best_loss:\n",
    "            best_loss = loss_val.item()\n",
    "            best_params = [p.detach().clone() for p in params]\n",
    "            \n",
    "        # Print epoch and loss information\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss_val.item():.4f}\")\n",
    "            \n",
    "        # Check if loss is below threshold\n",
    "        if loss_val.item() < loss_threshold:\n",
    "            print(f\"\\nTraining converged with loss {loss_val.item():.4f} below threshold {loss_threshold}\")\n",
    "            break\n",
    "            \n",
    "    except RuntimeError as e:\n",
    "        print(f\"\\nOptimization failed at epoch {epoch+1}: {str(e)}\")\n",
    "        break\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\nTraining completed in {training_time:.2f} seconds\")\n",
    "\n",
    "# Restore best parameters if available\n",
    "if best_params is not None:\n",
    "    for p, best_p in zip(params, best_params):\n",
    "        p.data.copy_(best_p)\n",
    "\n",
    "# Ensure we have the final states for analysis\n",
    "if state.traj_states is None or state.fixed_point_inits is None:\n",
    "    print(\"Running final batch to get states for analysis...\")\n",
    "    _, state.traj_states, state.fixed_point_inits = run_batch(J_param, B_param, b_x_param, w_param, b_z_param)\n",
    "\n",
    "# Plot produced trajectories vs. target signals for selected tasks\n",
    "test_js = [0, 10, 20, 30, 40, 50]\n",
    "fig, axes = plt.subplots(nrows=len(test_js), ncols=1, figsize=(10, 3 * len(test_js)))\n",
    "if len(test_js) == 1:\n",
    "    axes = [axes]  # Ensure axes is iterable when there's a single subplot\n",
    "\n",
    "for ax, j in zip(axes, test_js):\n",
    "    omega = omegas[j]\n",
    "    u_offset = static_inputs[j]\n",
    "    \n",
    "    # Build the training input and compute the target sine signal.\n",
    "    u_train_test = torch.full((num_steps_train, 1), u_offset, dtype=torch.float32, device=device)\n",
    "    target_train_test = np.sin(omega * time_train)\n",
    "    \n",
    "    # Initialize state using driving phase.\n",
    "    x0_test = torch.zeros(N, device=device)\n",
    "    u_drive_test = torch.tensor(np.sin(omega*time_drive) + u_offset, \n",
    "                                dtype=torch.float32, device=device).view(-1, 1)\n",
    "    xs_drive_test, _ = simulate_trajectory(x0_test, u_drive_test, J_param, B_param, \n",
    "                                           b_x_param, w_param, b_z_param, dt)\n",
    "    x_drive_final_test = xs_drive_test[-1]\n",
    "    \n",
    "    # Simulate training phase starting from the drive-phase final state.\n",
    "    _, zs_train_test = simulate_trajectory(x_drive_final_test, u_train_test, J_param, B_param, \n",
    "                                           b_x_param, w_param, b_z_param, dt)\n",
    "    produced_traj = zs_train_test.detach().cpu().numpy()\n",
    "    \n",
    "    # Plot the produced trajectory and the target signal.\n",
    "    ax.plot(time_train, produced_traj, label=\"Produced Output\", linewidth=2)\n",
    "    ax.plot(time_train, target_train_test, 'k--', label=\"Target Signal\", linewidth=1.5)\n",
    "    ax.set_title(f\"Task {j}: omega = {omega:.3f}, u_offset = {u_offset:.3f}\")\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"Output\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Post-Training Analysis: Fixed point search & Unstable Mode Frequencies\n",
    "# -------------------------------\n",
    "def fixed_point_func(x_np, u_val, J_np, B_np, b_x_np):\n",
    "    \"\"\"\n",
    "    Compute f(x) = -x + J*tanh(x) + B*u + b_x for given x and fixed u.\n",
    "    Vectorized implementation for better performance.\n",
    "    \"\"\"\n",
    "    x = x_np\n",
    "    return -x + np.dot(J_np, np.tanh(x)) + np.dot(B_np, np.array([u_val])).flatten() + b_x_np\n",
    "\n",
    "def jacobian_fixed_point(x_star, J_np):\n",
    "    \"\"\"\n",
    "    Compute Jacobian: J_eff = -I + J * diag(1 - tanh(x_star)^2)\n",
    "    Vectorized implementation for better performance.\n",
    "    \"\"\"\n",
    "    diag_term = 1 - np.tanh(x_star)**2\n",
    "    return -np.eye(len(x_star)) + J_np * diag_term[np.newaxis, :]\n",
    "\n",
    "# Extract trained parameters as NumPy arrays\n",
    "J_trained = J_param.detach().cpu().numpy()\n",
    "B_trained = B_param.detach().cpu().numpy()\n",
    "b_x_trained = b_x_param.detach().cpu().numpy()\n",
    "\n",
    "def find_fixed_points(x0_guess, u_const, J_trained, B_trained, b_x_trained, num_attempts=10, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Find multiple fixed points by trying different initial conditions.\n",
    "    \n",
    "    Arguments:\n",
    "        x0_guess: Initial guess for fixed point\n",
    "        u_const: Constant input\n",
    "        J_trained, B_trained, b_x_trained: Network parameters\n",
    "        num_attempts: Number of different initial conditions to try\n",
    "        tol: Tolerance for considering two fixed points as distinct\n",
    "        \n",
    "    Returns:\n",
    "        List of distinct fixed points found\n",
    "    \"\"\"\n",
    "    fixed_points = []\n",
    "    \n",
    "    # Try the original initial condition\n",
    "    try:\n",
    "        sol = root(fixed_point_func, x0_guess, args=(u_const, J_trained, B_trained, b_x_trained),\n",
    "                  method='lm', options={'maxiter': 1000})\n",
    "        if sol.success:\n",
    "            fixed_points.append(sol.x)\n",
    "    except Exception as e:\n",
    "        print(f\"Fixed point search failed for initial guess: {str(e)}\")\n",
    "    \n",
    "    # Try perturbed initial conditions\n",
    "    for attempt in tqdm(range(num_attempts - 1), desc=\"Finding fixed points\", leave=False):\n",
    "        # Create a perturbed initial condition\n",
    "        x0_perturbed = x0_guess + np.random.normal(0, 0.5, size=x0_guess.shape)\n",
    "        try:\n",
    "            sol = root(fixed_point_func, x0_perturbed, args=(u_const, J_trained, B_trained, b_x_trained),\n",
    "                      method='lm', options={'maxiter': 1000})\n",
    "            if sol.success:\n",
    "                # Check if this fixed point is distinct from previous ones\n",
    "                is_distinct = True\n",
    "                for fp in fixed_points:\n",
    "                    if np.linalg.norm(sol.x - fp) < tol:\n",
    "                        is_distinct = False\n",
    "                        break\n",
    "                if is_distinct:\n",
    "                    fixed_points.append(sol.x)\n",
    "        except Exception as e:\n",
    "            print(f\"Fixed point search failed for attempt {attempt+1}: {str(e)}\")\n",
    "    \n",
    "    return fixed_points\n",
    "\n",
    "def analyze_fixed_points(fixed_points, J_trained, static_inputs):\n",
    "    \"\"\"\n",
    "    Analyze fixed points and compute their properties in a memory-efficient way.\n",
    "    \"\"\"\n",
    "    jacobians = []\n",
    "    unstable_freqs = []\n",
    "    \n",
    "    for x_star in fixed_points:\n",
    "        # Compute Jacobian at the fixed point\n",
    "        J_eff = jacobian_fixed_point(x_star, J_trained)\n",
    "        jacobians.append(J_eff)\n",
    "        \n",
    "        # Compute eigenvalues\n",
    "        eigenvals, _ = eig(J_eff)\n",
    "        \n",
    "        # Find unstable eigenvalues\n",
    "        idx_complex = np.where((np.abs(np.imag(eigenvals)) > 1e-3) & (np.real(eigenvals) > 0))[0]\n",
    "        if len(idx_complex) > 0:\n",
    "            # Sort by imaginary part magnitude and take the largest\n",
    "            sorted_idx = idx_complex[np.argsort(np.abs(np.imag(eigenvals[idx_complex])))]\n",
    "            ev = eigenvals[sorted_idx[-1]]  # take the one with largest imaginary part\n",
    "            unstable_freqs.append(np.abs(np.imag(ev)))\n",
    "        else:\n",
    "            unstable_freqs.append(0.0)\n",
    "    \n",
    "    return jacobians, unstable_freqs\n",
    "\n",
    "# Initialize lists to store multiple fixed points and their properties\n",
    "all_fixed_points = []  # List of lists, one list per task\n",
    "all_jacobians = []     # List of lists of Jacobians\n",
    "all_unstable_eig_freq = []  # List of lists of unstable frequencies\n",
    "\n",
    "# Track fixed point search time\n",
    "start_time = time.time()\n",
    "print(\"\\nStarting fixed point search...\")\n",
    "\n",
    "# Process tasks in batches for memory efficiency\n",
    "batch_size = 5  # Adjust based on available memory\n",
    "for batch_start in range(0, num_tasks, batch_size):\n",
    "    batch_end = min(batch_start + batch_size, num_tasks)\n",
    "    \n",
    "    for j in range(batch_start, batch_end):\n",
    "        u_const = static_inputs[j]\n",
    "        x0_guess = state.fixed_point_inits[j]\n",
    "        \n",
    "        # Find multiple fixed points\n",
    "        task_fixed_points = find_fixed_points(x0_guess, u_const, J_trained, B_trained, b_x_trained)\n",
    "        all_fixed_points.append(task_fixed_points)\n",
    "        \n",
    "        # Analyze fixed points\n",
    "        task_jacobians, task_unstable_freqs = analyze_fixed_points(task_fixed_points, J_trained, static_inputs)\n",
    "        all_jacobians.append(task_jacobians)\n",
    "        all_unstable_eig_freq.append(task_unstable_freqs)\n",
    "        \n",
    "        # Clear memory\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "fixed_point_time = time.time() - start_time\n",
    "print(f\"\\nFixed point search completed in {fixed_point_time:.2f} seconds\")\n",
    "\n",
    "# Print summary of fixed points found\n",
    "print(\"\\nSummary of Fixed Points Found:\")\n",
    "for j in range(num_tasks):\n",
    "    print(f\"\\nTask {j} (omega = {omegas[j]:.3f}):\")\n",
    "    print(f\"Number of distinct fixed points found: {len(all_fixed_points[j])}\")\n",
    "    for i, (fp, freq) in enumerate(zip(all_fixed_points[j], all_unstable_eig_freq[j])):\n",
    "        print(f\"  Fixed point {i+1}:\")\n",
    "        print(f\"    Unstable mode frequency: {freq:.4f}\")\n",
    "        print(f\"    Norm: {np.linalg.norm(fp):.4f}\")\n",
    "\n",
    "# Plot unstable mode frequencies for the first fixed point of each task\n",
    "first_fixed_point_freqs = [freqs[0] if freqs else 0.0 for freqs in all_unstable_eig_freq]\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(omegas, first_fixed_point_freqs, 'o-', label='|Imag(eigenvalue)| (unstable mode)')\n",
    "plt.plot(omegas, omegas, 'k--', label='Target frequency')\n",
    "plt.xlabel('Target Frequency (rad/s)')\n",
    "plt.ylabel('Frequency from Linearization (rad/s)')\n",
    "plt.title('Comparison of Target Frequencies and Unstable Mode Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# Additional Analysis: Jacobian and Parameter Visualization for Selected Tasks\n",
    "# -------------------------------\n",
    "test_js = [0, 10, 20, 30, 40, 50]\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y']\n",
    "markers = ['o', 's', '^', 'v', '<', '>']\n",
    "\n",
    "# Print detailed information about unstable eigenvalues for all tasks\n",
    "print(\"\\nDetailed Analysis of Unstable Eigenvalues:\")\n",
    "for j in range(num_tasks):\n",
    "    print(f\"\\nTask {j} (omega = {omegas[j]:.3f}):\")\n",
    "    for i, (J_eff, freqs) in enumerate(zip(all_jacobians[j], all_unstable_eig_freq[j])):\n",
    "        eigenvals, _ = eig(J_eff)\n",
    "        unstable_idx = np.where(np.real(eigenvals) > 0)[0]\n",
    "        num_unstable = len(unstable_idx)\n",
    "        \n",
    "        print(f\"\\n  Fixed point {i+1}:\")\n",
    "        print(f\"  Number of unstable eigenvalues: {num_unstable}\")\n",
    "        if num_unstable > 0:\n",
    "            unstable_eigenvals = eigenvals[unstable_idx]\n",
    "            print(\"  Unstable eigenvalues:\")\n",
    "            for ev in unstable_eigenvals:\n",
    "                print(f\"    Real: {np.real(ev):.4f}, Imag: {np.imag(ev):.4f}\")\n",
    "\n",
    "# Plot unstable eigenvalues for selected tasks\n",
    "plt.figure(figsize=(12, 8))\n",
    "for idx, j in enumerate(test_js):\n",
    "    for i, (J_eff, freqs) in enumerate(zip(all_jacobians[j], all_unstable_eig_freq[j])):\n",
    "        eigenvals, _ = eig(J_eff)\n",
    "        unstable_idx = np.where(np.real(eigenvals) > 0)[0]\n",
    "        unstable_eigenvals = eigenvals[unstable_idx]\n",
    "        \n",
    "        if len(unstable_eigenvals) > 0:\n",
    "            plt.scatter(np.real(unstable_eigenvals), np.imag(unstable_eigenvals), \n",
    "                       color=colors[idx], marker=markers[i], \n",
    "                       label=f'Task {j} FP{i+1} (ω={omegas[j]:.3f})')\n",
    "\n",
    "plt.axvline(x=0, color='k', linestyle='--', alpha=0.3)\n",
    "plt.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "plt.xlabel('Real Part')\n",
    "plt.ylabel('Imaginary Part')\n",
    "plt.title('Unstable Eigenvalues of Jacobian for Selected Tasks')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Create subplots for Jacobian visualizations\n",
    "num_rows = len(test_js)\n",
    "fig, axes = plt.subplots(num_rows, 2, figsize=(15, 5*num_rows))\n",
    "fig.suptitle('Jacobian and Parameter Matrices for Selected Tasks', fontsize=16)\n",
    "\n",
    "# Plot Jacobians and parameters for each selected task\n",
    "for idx, j in enumerate(test_js):\n",
    "    if all_jacobians[j]:  # If any fixed points were found\n",
    "        # Plot first Jacobian for this task\n",
    "        im = axes[idx, 0].imshow(all_jacobians[j][0], cmap='viridis')\n",
    "        axes[idx, 0].set_title(f'Jacobian Matrix (Task {j}, ω={omegas[j]:.3f}, FP1)')\n",
    "        plt.colorbar(im, ax=axes[idx, 0])\n",
    "        \n",
    "        # Plot J_param (only for first row)\n",
    "        if idx == 0:\n",
    "            im = axes[idx, 1].imshow(J_param.detach().cpu().numpy(), cmap='viridis')\n",
    "            axes[idx, 1].set_title('J_param Matrix')\n",
    "            plt.colorbar(im, ax=axes[idx, 1])\n",
    "        else:\n",
    "            axes[idx, 1].axis('off')\n",
    "    else:\n",
    "        axes[idx, 0].axis('off')\n",
    "        axes[idx, 1].axis('off')\n",
    "\n",
    "# Add B_param and b_x_param visualizations\n",
    "fig2, axes2 = plt.subplots(2, 1, figsize=(10, 10))\n",
    "fig2.suptitle('Parameter Matrices', fontsize=16)\n",
    "\n",
    "# Plot B_param\n",
    "im = axes2[0].imshow(B_param.detach().cpu().numpy(), cmap='viridis')\n",
    "axes2[0].set_title('B_param Matrix')\n",
    "plt.colorbar(im, ax=axes2[0])\n",
    "\n",
    "# Plot b_x_param\n",
    "im = axes2[1].imshow(b_x_param.detach().cpu().numpy().reshape(-1, 1), cmap='viridis')\n",
    "axes2[1].set_title('b_x_param Vector')\n",
    "plt.colorbar(im, ax=axes2[1])\n",
    "\n",
    "# Print information about state.traj_states and state.fixed_point_inits\n",
    "print(\"\\nState Information:\")\n",
    "print(f\"state.traj_states:\")\n",
    "print(f\"  Type: {type(state.traj_states)}\")\n",
    "print(f\"  Length: {len(state.traj_states)}\")\n",
    "print(f\"  Shape of first trajectory: {state.traj_states[0].shape}\")\n",
    "print(f\"  Data type of first trajectory: {state.traj_states[0].dtype}\")\n",
    "\n",
    "print(f\"\\nstate.fixed_point_inits:\")\n",
    "print(f\"  Type: {type(state.fixed_point_inits)}\")\n",
    "print(f\"  Length: {len(state.fixed_point_inits)}\")\n",
    "print(f\"  Shape of first fixed point: {state.fixed_point_inits[0].shape}\")\n",
    "print(f\"  Data type of first fixed point: {state.fixed_point_inits[0].dtype}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# 6. PCA and Visualization\n",
    "# -------------------------------\n",
    "# Track PCA computation time\n",
    "start_time = time.time()\n",
    "print(\"\\nStarting PCA computation...\")\n",
    "\n",
    "# Concatenate all states from all tasks (from training phase) to perform PCA.\n",
    "all_states = np.concatenate([traj for traj in state.traj_states], axis=0)\n",
    "pca = PCA(n_components=3)\n",
    "proj_all = pca.fit_transform(all_states)\n",
    "\n",
    "# For plotting, also project each trajectory and each fixed point into PCA space.\n",
    "proj_trajs = []\n",
    "start = 0\n",
    "for traj in tqdm(state.traj_states, desc=\"Projecting trajectories\"):\n",
    "    T = traj.shape[0]\n",
    "    proj_traj = proj_all[start:start+T]\n",
    "    proj_trajs.append(proj_traj)\n",
    "    start += T\n",
    "\n",
    "# Project all fixed points from all tasks\n",
    "all_fixed_points_flat = []\n",
    "for task_fps in all_fixed_points:\n",
    "    all_fixed_points_flat.extend(task_fps)\n",
    "proj_fixed = pca.transform(np.array(all_fixed_points_flat))\n",
    "\n",
    "pca_time = time.time() - start_time\n",
    "print(f\"\\nPCA computation completed in {pca_time:.2f} seconds\")\n",
    "\n",
    "# Plot trajectories (blue) and fixed points (green circles) with unstable eigen-directions (red lines)\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for traj in proj_trajs:\n",
    "    ax.plot(traj[:,0], traj[:,1], traj[:,2], color='blue', alpha=0.5)\n",
    "    \n",
    "# Plot fixed points as green circles\n",
    "ax.scatter(proj_fixed[:,0], proj_fixed[:,1], proj_fixed[:,2], color='green', s=50, label=\"Fixed Points\")\n",
    "\n",
    "# For each fixed point, plot the unstable mode as a red line.\n",
    "fixed_point_idx = 0\n",
    "for j, task_fps in enumerate(all_fixed_points):\n",
    "    for x_star in task_fps:\n",
    "        u_const = static_inputs[j]\n",
    "        J_eff = jacobian_fixed_point(x_star, J_trained)\n",
    "        eigenvals, eigenvecs = eig(J_eff)\n",
    "        idx_complex = np.where((np.abs(np.imag(eigenvals)) > 1e-3) & (np.real(eigenvals) > 0))[0]\n",
    "        if len(idx_complex) > 0:\n",
    "            # Sort by imaginary part magnitude and take the largest\n",
    "            sorted_idx = idx_complex[np.argsort(np.abs(np.imag(eigenvals[idx_complex])))]\n",
    "            v = eigenvecs[:, sorted_idx[-1]].real  # take real part for plotting direction\n",
    "            # Scale vector for visualisation\n",
    "            scale = 0.5  \n",
    "            # Project the unstable eigenvector into PCA space\n",
    "            v_proj = pca.transform((x_star + scale * v).reshape(1, -1))[0] - proj_fixed[fixed_point_idx]\n",
    "            # Plot a line centered on the fixed point\n",
    "            line = np.array([proj_fixed[fixed_point_idx] - v_proj, proj_fixed[fixed_point_idx] + v_proj])\n",
    "            ax.plot(line[:,0], line[:,1], line[:,2], color='red', linewidth=2)\n",
    "        fixed_point_idx += 1\n",
    "    \n",
    "ax.set_title('PCA of Network Trajectories and Fixed Points')\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
